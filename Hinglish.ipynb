{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt74yKbNgRy6AJ6w6n5fEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pixiedust57/English_Hinglish/blob/main/Hinglish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U8UH2qeNvZGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d525745e-9969-41f6-fdd5-084105fb1df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas openai requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Set up the OpenAI API\n",
        "openai.api_key = \"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\"\n",
        "GPT_API_URL = \"https://api.openai.com/v1/chat/completions\""
      ],
      "metadata": {
        "id": "oGiDcml2vj_J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "r4xTbQV2v-hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69ff17d-0791-4802-f999-f89fd2bada56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-transliteration"
      ],
      "metadata": {
        "id": "MUES6T8PH30K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c9fefa-9462-4830-d8fc-42854828478b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: indic-transliteration in /usr/local/lib/python3.10/dist-packages (2.3.52)\n",
            "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (1.6.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2023.6.3)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (4.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langdetect import detect\n",
        "\n",
        "# Set your OpenAI API key\n",
        "api_key = \"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\"\n",
        "\n",
        "# Initialize the OpenAI API client\n",
        "openai.api_key = api_key\n",
        "GPT_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "# Function to translate English to Hinglish\n",
        "def translate_to_hinglish(english_text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use the GPT-3.5 Turbo model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Create a Hinglish translation from English text. The text should sound natural and also convert all the difficult words and phrases in English to Hinglish. This converted text should be easy to understand for even a non-native Hindi speaker.\"},\n",
        "            {\"role\": \"user\", \"content\": english_text}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    hinglish_translation = response.choices[0].message[\"content\"].strip() if response.choices else \"Translation failed\"\n",
        "\n",
        "# Only perform language detection if the text is reasonably long\n",
        "    if len(hinglish_translation) > 5:\n",
        "        try:\n",
        "            from langdetect import detect\n",
        "            # Split the translated text into words and check for English words\n",
        "            translated_words = hinglish_translation.split()\n",
        "            for i, word in enumerate(translated_words):\n",
        "                if detect(word) == \"en\":\n",
        "                    translated_words[i] = word  # Replace the detected English word\n",
        "            return \" \".join(translated_words)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return hinglish_translation\n",
        "\n",
        "\n",
        "\n",
        "# Input and output file paths\n",
        "input_file_path = \"input.txt\"\n",
        "output_file_path = \"output.txt\"\n",
        "\n",
        "# Read input from the English text file\n",
        "with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
        "    english_sentences = input_file.readlines()\n",
        "\n",
        "# Translate each sentence to Hinglish and write the output to a new file\n",
        "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
        "    for sentence in english_sentences:\n",
        "        hinglish_translation = translate_to_hinglish(sentence)\n",
        "        output_file.write(hinglish_translation + \"\\n\")\n",
        "\n",
        "print(\"Translation completed. Check 'output.txt' for the translated text.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNCX1M-A1BBz",
        "outputId": "bef22859-8b64-44c9-e609-fda219611c26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation completed. Check 'output.txt' for the translated text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate\n",
        "from langdetect import detect\n",
        "# Google Transliteration API endpoint\n",
        "google_transliteration_api = \"https://inputtools.google.com/request?text={text}&ime=transliteration_en_te\"\n",
        "\n",
        "def transliterate_to_hindi(sentence):\n",
        "    words = sentence.split()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if detect(word) == \"hi\":\n",
        "            # Transliterate Hindi words to Devanagari using the indic-transliteration library\n",
        "            hindi_word = xsanscript.transliterate(word, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
        "            new_words.append(hindi_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Function to translate text using GPT-3.5 Turbo\n",
        "def translate_to_hinglish(sentence):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Convert the following hindi words in english to hindi language and leave english words in english language.\"},\n",
        "            {\"role\": \"user\", \"content\": sentence}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    hinglish_translation = response.choices[0].message[\"content\"]\n",
        "\n",
        "    return hinglish_translation\n",
        "\n",
        "# Input and output file paths\n",
        "input_file_path = \"output.txt\"\n",
        "output_file_path = \"output2.txt\"\n",
        "\n",
        "# Read input from the text file\n",
        "with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
        "    hindi_sentences = input_file.readlines()\n",
        "\n",
        "# Translate and write the output to a new file\n",
        "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
        "    for sentence in hindi_sentences:\n",
        "        transliterated_sentence = transliterate_to_hindi(sentence)\n",
        "        hinglish_translation = translate_to_hinglish(transliterated_sentence)\n",
        "        output_file.write(hinglish_translation + \"\\n\")\n",
        "\n",
        "print(\"Translation completed. Check 'output.txt' for the Hinglish text.\")"
      ],
      "metadata": {
        "id": "OistkOzv8cTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71086cc-62ea-41f2-93df-2ef456dc6951"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation completed. Check 'output.txt' for the Hinglish text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output2.txt\", \"r\") as input_file:\n",
        "    input_sentences = input_file.readlines()\n",
        "\n",
        "# Initialize an empty list to store the translated sentences\n",
        "translated_sentences = []\n",
        "\n",
        "# Translate each sentence\n",
        "for in_sentence in input_sentences:\n",
        "    in_sentence = in_sentence.strip()  # Remove newline character\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"convert the following sentence to a mix of Hindi and certain words in English  : \"},\n",
        "            {\"role\": \"user\", \"content\": in_sentence}\n",
        "        ],\n",
        "        max_tokens=50,\n",
        "        api_key=api_key\n",
        "    )\n",
        "    translated_sentence = response['choices'][0]['message']['content'].strip()\n",
        "    translated_sentences.append(translated_sentence)\n",
        "\n",
        "# Write the translated sentences to an output file\n",
        "with open(\"outputfinal.txt\", \"w\") as output_file:\n",
        "    for translated_sentence in translated_sentences:\n",
        "        output_file.write(translated_sentence + \"\\n\")\n",
        "\n",
        "print(\"Translations completed. Output saved to output.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zKTvsyHfB-t",
        "outputId": "33a3d860-162f-4bf8-cbc4-6e4d067c3019"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translations completed. Output saved to output.txt\n"
          ]
        }
      ]
    }
  ]
}